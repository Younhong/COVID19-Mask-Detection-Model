{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Argument setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = argparse.ArgumentParser()   #  --를 인식함.    외부 데이터 불러들이기\n",
    "\n",
    "ap.add_argument(\"-f\", -face\"-\", type=str,   #외부에서  --face, --model, 그리고 --confidence의 데이터를 받아옴.\n",
    "    default=\"face_detector\",\n",
    "    help=\"path to face detector model directory\")    #--face의 데이터는 face_detector에 추가합니다.\n",
    "    \n",
    "ap.add_argument(\"-m\", \"--model\", type=str,\n",
    "    default=\"mask_detector.model\",\n",
    "    help=\"path to trained face mask detector model\")      #--model의 데이터는 mask_detector.model에 추가합니다.\n",
    "    \n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "    help=\"minimum probability to filter weak detections\")    \n",
    "    \n",
    "args = vars(ap.parse_args())   #마지막으로 args에 각각의 데이터들을 업데이트해줍니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. detect_and_predict_mask 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_predict_mask(frame, faceNet, maskNet):\n",
    "    (h, w) = frame.shape[:2]   #frame배열의 1,2번째 index값을 h(세로),w(가로)에 저장   #frame은 실시간 비디오의 화면\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),(104.0, 177.0, 123.0))  #이미지 가공해서 blob에 저장\n",
    "\n",
    "    faceNet.setInput(blob)  #blob에 저장된 가공한 이미지를 faceNet에 저장\n",
    "    detections = faceNet.forward()  #순방향으로 딥러닝 네트워크를 실행해 detection에 저장\n",
    "\n",
    "    faces = []  #얼굴을 모으는 리스트\n",
    "    locs = []   #box의 좌표를 모으는 리스트\n",
    "    preds = []  #마스크 예측한 것을 모으는 리스트\n",
    "    \n",
    "    for i in range(0, detections.shape[2]):  #200번 반복\n",
    "        confidence = detections[0, 0, i, 2]  #얼굴을 인식하고 마스크를 착용했는지에 대한 추측 정확도를 confidence에 저장\n",
    "                                              #detections는 실시간으로 찍히는 화면이 저장되는 것\n",
    "\n",
    "        if confidence > args[\"confidence\"]:   #기본값이 0.5로 설정. confidence가 크면 마스크를 잘 쓴 것.\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])  #detection에서 얼굴크기를 이용해 box의 네 모퉁이를 box에 저장.\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")  #box의 두 모퉁이 값을 정수로 바꿔서 좌표로 지정\n",
    "\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))   #좌표가 음수가 안나오게 하기 위함.\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))   #box가 화면 밖으로 안나가게 하기 위함.\n",
    "\n",
    "            face = frame[startY:endY, startX:endX]   #frame(배경+사람)에서 box크기 만클을 slicing 한 것을 face에 저장.\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face, (224, 224))   \n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "\n",
    "            faces.append(face)    #가공된 face가 faces에 추가됨.\n",
    "            locs.append((startX, startY, endX, endY))   #locs에는 box의 좌표가 추가됨.\n",
    "\n",
    "    if len(faces) > 0:   #저장된 얼굴의 개수가 1개 이상이면 얼굴 사진들을 넘파이 어레이로 만듦.\n",
    "        faces = np.array(faces, dtype=\"float32\")\n",
    "        preds = maskNet.predict(faces, batch_size=32)   #예측한 것(마스크를 착용했을 확률과 착용하지 않았을 확률)  \n",
    "\n",
    "    return  (locs,preds)  #box의 좌표들과 예측한 값을 return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. face_detector폴더 내의 파일들을 불러와 faceNet에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading face detector model...\")\n",
    "\n",
    "prototxtPath = os.path.sep.join([args[\"face\"], \"deploy.prototxt\"])   #\"deploy.prototxt\"파일을 불러와서 prototxtPath에 저장 \n",
    "\n",
    "weightsPath = os.path.sep.join([args[\"face\"],\"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)  #dnn(딥러닝 네트워크)를 사용해 prototxtPath와 weightPath를 faceNet에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. mask_detector.model을 불러와 maskNet에 저장, 비디오 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] loading face mask detector model...\")\n",
    "\n",
    "maskNet = load_model(args[\"model\"])      #mask_detector.model을 불러와서 model에 저장하고, 그 model을 maskNet이라는 변수에 저장.\n",
    "\n",
    "print(\"[INFO] starting video stream...\")\n",
    "\n",
    "vs = VideoStream(src=0).start()     #video stream을 초기화하고, 카메라 센서를 warm up시킴.\n",
    "\n",
    "time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 실시간 video를 읽어오고, q키를 누르면 video stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    frame = vs.read()  #실시간 화면이 frame\n",
    "    frame = imutils.resize(frame, width=1100)  #frame크기 조정\n",
    "\n",
    "    (locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)   #frame(화면)과 4,5번에서 얻은 faceNet,maskNet을 함수에 통과시킴.\n",
    "\n",
    "    maskCount = 0     #추가한 부분(8번째 줄~39번째 줄)\n",
    "    nonMaskCount = 0      #실시간으로 사람 수를 세기 위해 매번 초기화함.\n",
    "    for (box, pred) in zip(locs, preds):    #box의 좌표들이 있는 locs변수와 예측한 것이 모여있는 pred변수에서 각각 하나씩 세트로 보냄. \n",
    "        (startX, startY, endX, endY) = box   #box의 2점의 좌표\n",
    "        (mask, withoutMask) = pred   #마스크를 착용했을 확률, 착용하지 않았을 확률을 pred에 저장\n",
    "\n",
    "        if mask > withoutMask:   #반복문에 들어온 사람이 마스크를 착용했을 확률이 더 높다면 \n",
    "            maskCount += 1    \n",
    "        else:   \n",
    "            nonMaskCount += 1   #이렇게 매 순간 마스크를 착용한 사람과 착용하지 않을 사람의 수를 헤아린다.\n",
    "\n",
    "        label = \"Mask\" if mask > withoutMask else \"No Mask\"  #마스크를 착용했을 확률이 높다면 label에 Mask, 아니면 No Mask\n",
    "        color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)   #전자의 경우라면 초록색으로, 후자라면 빨간색으로 글자를 표시한다.\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100) \n",
    "        label2 = \"Good Job\" if mask > withoutMask else \"Warning[Wear Mask]\"   #착용 여부에 대한 반응을 해줌.\n",
    "\n",
    "       \n",
    "\n",
    "        \n",
    "        cv2.putText(frame, label, (startX, startY - 10)   #frame에 위의 label꾸며서 보이게 함.,                           \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)     \n",
    "        cv2.putText(frame, label2, (startX, endY + 20),   #frame에 위의 label2를 꾸며서 출력\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)      \n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY),color, 2)   #frame에 꾸민 box를 올림.\n",
    "\n",
    "    color2 = (0, 255, 0) if nonMaskCount == 0 else (0, 0, 255)    #한 명이라도 마스크를 착용하지 않았으면 빨간색으로 color지정\n",
    "    label3 = \"{}/{}\".format(maskCount, nonMaskCount + maskCount)     #몇 명 중, 몇 명이 마스크를 착용했는지에 대한 확률 계산\n",
    "    cv2.putText(frame, label3, (100, 130),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color2, 2)   #frame위에 color2색을 이용해 label3을 보여줌.\n",
    "\n",
    "    label4 = \"# of Wearing Masks/# of Detected\"   \n",
    "    cv2.putText(frame, label4, (100, 100), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 2)   #frame위에 label4를 보여줌.\n",
    "    \n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF   #사용자가 종료할 때 까지 기다림.\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break   #사용자가 'q'키를 누르면 실시간 비디오 종료된. \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "vs.stop()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
